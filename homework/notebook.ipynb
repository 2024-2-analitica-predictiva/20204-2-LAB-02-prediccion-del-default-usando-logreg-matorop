{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10748</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>84373</td>\n",
       "      <td>57779</td>\n",
       "      <td>14163</td>\n",
       "      <td>8295</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12574</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1690</td>\n",
       "      <td>1138</td>\n",
       "      <td>930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2828</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29677</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45975</td>\n",
       "      <td>1300</td>\n",
       "      <td>43987</td>\n",
       "      <td>0</td>\n",
       "      <td>46257</td>\n",
       "      <td>2200</td>\n",
       "      <td>1300</td>\n",
       "      <td>43987</td>\n",
       "      <td>1386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8857</td>\n",
       "      <td>80000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>40748</td>\n",
       "      <td>39816</td>\n",
       "      <td>40607</td>\n",
       "      <td>3700</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21099</td>\n",
       "      <td>270000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22448</td>\n",
       "      <td>15490</td>\n",
       "      <td>17343</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0  10748     310000    1          3         1   32      0      0      0   \n",
       "1  12574      10000    2          3         1   49     -1     -1     -2   \n",
       "2  29677      50000    1          2         1   28     -1     -1     -1   \n",
       "3   8857      80000    2          3         1   52      2      2      3   \n",
       "4  21099     270000    1          1         2   34      1      2      0   \n",
       "\n",
       "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0      0  ...      84373      57779      14163      8295      6000      4000   \n",
       "1     -1  ...       1690       1138        930         0         0      2828   \n",
       "2      0  ...      45975       1300      43987         0     46257      2200   \n",
       "3      3  ...      40748      39816      40607      3700      1600      1600   \n",
       "4      0  ...      22448      15490      17343         0      4000      2000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0      3000      1000      2000                           0  \n",
       "1         0       182         0                           1  \n",
       "2      1300     43987      1386                           0  \n",
       "3         0      1600      1600                           1  \n",
       "4         0      2000      2000                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Paso 1\n",
    "import pandas as pd\n",
    "\n",
    "df_train= pd.read_csv('../files/input/train_data.csv.zip')\n",
    "df_test= pd.read_csv('../files/input/test_data.csv.zip')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(columns={'default payment next month': 'default'})\n",
    "    df.drop('ID', axis=1, inplace=True)\n",
    "    df['EDUCATION'] = df['EDUCATION'].apply(lambda x: 4 if x>4 else x)\n",
    "    df= df.query('MARRIAGE != 0 and EDUCATION != 0')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = clean_dataset(df_train)\n",
    "df_test = clean_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL    0\n",
       "SEX          0\n",
       "EDUCATION    0\n",
       "MARRIAGE     0\n",
       "AGE          0\n",
       "PAY_0        0\n",
       "PAY_2        0\n",
       "PAY_3        0\n",
       "PAY_4        0\n",
       "PAY_5        0\n",
       "PAY_6        0\n",
       "BILL_AMT1    0\n",
       "BILL_AMT2    0\n",
       "BILL_AMT3    0\n",
       "BILL_AMT4    0\n",
       "BILL_AMT5    0\n",
       "BILL_AMT6    0\n",
       "PAY_AMT1     0\n",
       "PAY_AMT2     0\n",
       "PAY_AMT3     0\n",
       "PAY_AMT4     0\n",
       "PAY_AMT5     0\n",
       "PAY_AMT6     0\n",
       "default      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  y_train = df_train.drop('default', axis=1), df_train['default']\n",
    "X_test,  y_test = df_test.drop('default', axis=1), df_test['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3\n",
    "- Selecciona las K mejores caracteristicas.\n",
    "- Ajusta un modelo de regresion logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "\n",
    "columnas_categoricas = ['SEX','EDUCATION','MARRIAGE']\n",
    "columnas_numericas = list(set(X_train.columns.values) - set(columnas_categoricas))\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe', OneHotEncoder(dtype=np.int64), columnas_categoricas),\n",
    "        (\"scaler\", MinMaxScaler(), columnas_numericas)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('transformer', transformer),\n",
    "        (\"select_kbest\", SelectKBest(score_func=f_classif, k=\"all\")),\n",
    "        ('logisticregression', LogisticRegression(n_jobs=-1, random_state=2024, max_iter=1000))   \n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Paso 4.\n",
    "- Optimice los hiperparametros del pipeline usando validaciÃ³n cruzada.\n",
    "- Use 10 splits para la validaciÃ³n cruzada. Use la funciÃ³n de precision\n",
    "balanceada para medir la precisiÃ³n del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'logisticregression__C': [1],\n",
    "    'logisticregression__solver': ['lbfgs'],\n",
    "    'select_kbest__k': [1],\n",
    "    'select_kbest__score_func': [f_classif]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=10,\n",
    "    scoring='balanced_accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter grid for parameter 'select_kbest__k' needs to be a list or a numpy array, but got 1 (of type int) instead. Single values need to be wrapped in a list with one element.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#mejor modelo\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#from sklearnex import patch_sklearn, config_context\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#patch_sklearn()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#with config_context(target_offload=\"gpu:0\"):\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234\\Documents\\EspecializaciÃ³n\\Primer Semestre\\Materias\\Analitica Predictiva\\lab\\20204-2-LAB-02-prediccion-del-default-usando-logreg-matorop\\.venv\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\1234\\Documents\\EspecializaciÃ³n\\Primer Semestre\\Materias\\Analitica Predictiva\\lab\\20204-2-LAB-02-prediccion-del-default-usando-logreg-matorop\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\1234\\Documents\\EspecializaciÃ³n\\Primer Semestre\\Materias\\Analitica Predictiva\\lab\\20204-2-LAB-02-prediccion-del-default-usando-logreg-matorop\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     evaluate_candidates(\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\1234\\Documents\\EspecializaciÃ³n\\Primer Semestre\\Materias\\Analitica Predictiva\\lab\\20204-2-LAB-02-prediccion-del-default-usando-logreg-matorop\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:132\u001b[0m, in \u001b[0;36mParameterGrid.__init__\u001b[1;34m(self, param_grid)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter array for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m should be one-dimensional, got:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m     )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    130\u001b[0m     value, (np\u001b[38;5;241m.\u001b[39mndarray, Sequence)\n\u001b[0;32m    131\u001b[0m ):\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter grid for parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m needs to be a list or a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m numpy array, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) instead. Single values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to be wrapped in a list with one element.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter grid for parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m need \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto be a non-empty sequence, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Parameter grid for parameter 'select_kbest__k' needs to be a list or a numpy array, but got 1 (of type int) instead. Single values need to be wrapped in a list with one element."
     ]
    }
   ],
   "source": [
    "#mejor modelo\n",
    "#from sklearnex import patch_sklearn, config_context\n",
    "#patch_sklearn()\n",
    "\n",
    "#with config_context(target_offload=\"gpu:0\"):\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforest__bootstrap': True,\n",
       " 'randomforest__max_depth': None,\n",
       " 'randomforest__max_features': 'sqrt',\n",
       " 'randomforest__min_samples_leaf': 2,\n",
       " 'randomforest__min_samples_split': 10,\n",
       " 'randomforest__n_estimators': 180}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 5.\n",
    "-Guarde el modelo como \"files/models/model.pkl\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "models_dir = '../files/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "with gzip.open('../files/models/model.pkl.gz', 'wb') as file:\n",
    "    pickle.dump(grid_search, file)\n",
    "\n",
    "#with open('../files/model.pkl', 'wb') as file:\n",
    "    #pickle.dump(grid_search, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 6.\n",
    "Calcule las metricas de precision, precision balanceada, recall,\n",
    "y f1-score para los conjuntos de entrenamiento y prueba.\n",
    "Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    "del archivo es un diccionario con las metricas de un modelo.\n",
    "Este diccionario tiene un campo para indicar si es el conjunto\n",
    "de entrenamiento o prueba. Por ejemplo:\n",
    "\n",
    "{'dataset': 'train', 'precision': 0.8, 'balanced_accuracy': 0.7, 'recall': 0.9, 'f1_score': 0.85}\n",
    "{'dataset': 'test', 'precision': 0.7, 'balanced_accuracy': 0.6, 'recall': 0.8, 'f1_score': 0.75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, balanced_accuracy_score,\n",
    "    recall_score, f1_score, confusion_matrix, classification_report)\n",
    "np.set_printoptions(legacy='1.25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo_predecir(data):\n",
    "    import pickle\n",
    "    import gzip\n",
    "    with gzip.open(\"../files/models/model.pkl.gz\", \"rb\") as file:\n",
    "        estimator = pickle.load(file)\n",
    "        \n",
    "\n",
    "    return estimator.predict(data)\n",
    "\n",
    "#def cargar_modelo(data):\n",
    "    #import pickle\n",
    "    #with open(\"../files/models/model.pkl\", \"rb\") as file:\n",
    "    #     estimator = pickle.load(file)\n",
    "\n",
    "    # return estimator.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = grid_search.predict(X_train)\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "\n",
    "def eval_metrics(dataset,y_true, y_pred):\n",
    "    accuracy = precision_score(y_true, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return {'type': 'metrics','dataset': dataset, 'precision': accuracy, 'balanced_accuracy': balanced_accuracy, 'recall': recall, 'f1_score': f1} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_train = eval_metrics('train',y_train,y_train_pred)\n",
    "metrics_test = eval_metrics('test',y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Paso 7.\n",
    "-Calcule las matrices de confusion para los conjuntos de entrenamiento y\n",
    "prueba. Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    "del archivo es un diccionario con las metricas de un modelo.\n",
    "de entrenamiento o prueba. Por ejemplo:\n",
    "\n",
    "{'type': 'cm_matrix', 'dataset': 'train', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 666}, 'true_1': {\"predicted_0\": 3333, \"predicted_1\": 1444}}\n",
    "{'type': 'cm_matrix', 'dataset': 'test', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 650}, 'true_1': {\"predicted_0\": 2490, \"predicted_1\": 1420}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M.Confu - Entrenamiento:\n",
      "[[16097   131]\n",
      " [ 1864  2861]]\n",
      "M.Confu - Prueba:\n",
      "[[6678  395]\n",
      " [1133  773]]\n"
     ]
    }
   ],
   "source": [
    "# Matrices de confusiÃ³n\n",
    "print(\"M.Confu - Entrenamiento:\")\n",
    "cm_train=confusion_matrix(y_train, y_train_pred)\n",
    "print(cm_train)\n",
    "\n",
    "print(\"M.Confu - Prueba:\")\n",
    "cm_test=confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train_dict = {\n",
    "    'type': 'cm_matrix',\n",
    "    'dataset': 'train',\n",
    "    'true_0': {\n",
    "        'predicted_0': cm_train[0,0],\n",
    "        'predicted_1': cm_train[0,1]\n",
    "    },\n",
    "    'true_1': {\n",
    "        'predicted_0': cm_train[1,0],\n",
    "        'predicted_1': cm_train[1,1]\n",
    "    }\n",
    "}\n",
    "\n",
    "cm_test_dict = {\n",
    "    'type': 'cm_matrix',\n",
    "    'dataset': 'test',\n",
    "    'true_0': {\n",
    "        'predicted_0': cm_test[0,0],\n",
    "        'predicted_1': cm_test[0,1]\n",
    "    },\n",
    "    'true_1': {\n",
    "        'predicted_0': cm_test[1,0],\n",
    "        'predicted_1': cm_test[1,1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "models_dir = '../files/output'\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../files/output/metrics.json', mode='a') as file:\n",
    "    file.write(str(metrics_train).replace(\"'\",'\"')+\"\\n\")\n",
    "    file.write(str(metrics_test).replace(\"'\",'\"')+\"\\n\")\n",
    "    file.write(str(cm_train_dict).replace(\"'\",'\"')+\"\\n\")\n",
    "    file.write(str(cm_test_dict).replace(\"'\",'\"')+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
